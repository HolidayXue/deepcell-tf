{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Nuclear Segmentation with Mask-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (5760, 216, 256, 1)\n",
      "y.shape: (5760, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download the data (saves to ~/.keras/datasets)\n",
    "filename = 'HeLa_S3.npz'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.hela_s3.load_data(filename)\n",
    "\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the data file is currently required for `train_model_()` functions\n",
    "\n",
    "# NOTE: Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "model_name = 'mrcnn_model'\n",
    "backbone = 'vgg16'  # vgg16, vgg19, resnet50, densenet121, densenet169, densenet201\n",
    "\n",
    "n_epoch = 10  # Number of training epochs\n",
    "test_size = .20  # % of data saved as test\n",
    "lr = 1e-5\n",
    "\n",
    "optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=lr, decay=0.99)\n",
    "\n",
    "batch_size = 1  # loss can only handle one batch at a time.\n",
    "\n",
    "num_classes = 1  # \"object\" is the only class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MaskRCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "model = model_zoo.MaskRCNN(\n",
    "    backbone=backbone,\n",
    "#     crop_size=(27,32),\n",
    "    input_shape=X_train.shape[1:],\n",
    "    class_specific_filter=True,\n",
    "    num_classes=num_classes)\n",
    "\n",
    "prediction_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from deepcell import losses\n",
    "\n",
    "sigma = 3.0\n",
    "alpha = 0.25\n",
    "gamma = 2.0\n",
    "\n",
    "def regress_loss(y_true, y_pred):\n",
    "    # separate target and state\n",
    "    regression = y_pred\n",
    "    regression_target = y_true[..., :-1]\n",
    "    anchor_state = y_true[..., -1]\n",
    "\n",
    "    # filter out \"ignore\" anchors\n",
    "    indices = tf.where(K.equal(anchor_state, 1))\n",
    "    regression = tf.gather_nd(regression, indices)\n",
    "    regression_target = tf.gather_nd(regression_target, indices)\n",
    "\n",
    "    # compute the loss\n",
    "    loss = losses.smooth_l1(regression_target, regression, sigma=sigma)\n",
    "\n",
    "    # compute the normalizer: the number of positive anchors\n",
    "    normalizer = K.maximum(1, K.shape(indices)[0])\n",
    "    normalizer = K.cast(normalizer, dtype=K.floatx())\n",
    "\n",
    "    return K.sum(loss) / normalizer\n",
    "\n",
    "def classification_loss(y_true, y_pred):\n",
    "    # TODO: try weighted_categorical_crossentropy\n",
    "    labels = y_true[..., :-1]\n",
    "    # -1 for ignore, 0 for background, 1 for object\n",
    "    anchor_state = y_true[..., -1]\n",
    "\n",
    "    classification = y_pred\n",
    "    # filter out \"ignore\" anchors\n",
    "    indices = tf.where(K.not_equal(anchor_state, -1))\n",
    "    labels = tf.gather_nd(labels, indices)\n",
    "    classification = tf.gather_nd(classification, indices)\n",
    "\n",
    "    # compute the loss\n",
    "    loss = losses.focal(labels, classification, alpha=alpha, gamma=gamma)\n",
    "\n",
    "    # compute the normalizer: the number of positive anchors\n",
    "    normalizer = tf.where(K.equal(anchor_state, 1))\n",
    "    normalizer = K.cast(K.shape(normalizer)[0], K.floatx())\n",
    "    normalizer = K.maximum(K.cast_to_floatx(1.0), normalizer)\n",
    "\n",
    "    return K.sum(loss) / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.retinanet_anchor_utils import overlap\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "\n",
    "def mask_loss(y_true, y_pred):\n",
    "\n",
    "    def _mask(y_true, y_pred, iou_threshold=0.5, mask_size=(28, 28)):\n",
    "        # split up the different predicted blobs\n",
    "        boxes = y_pred[:, :, :4]\n",
    "        masks = y_pred[:, :, 4:]\n",
    "\n",
    "        # split up the different blobs\n",
    "        annotations = y_true[:, :, :5]\n",
    "        width = K.cast(y_true[0, 0, 5], dtype='int32')\n",
    "        height = K.cast(y_true[0, 0, 6], dtype='int32')\n",
    "        masks_target = y_true[:, :, 7:]\n",
    "\n",
    "        # reshape the masks back to their original size\n",
    "        masks_target = K.reshape(masks_target, (K.shape(masks_target)[0],\n",
    "                                                K.shape(masks_target)[1],\n",
    "                                                height, width))\n",
    "\n",
    "        masks = K.reshape(masks, (K.shape(masks)[0], K.shape(masks)[1],\n",
    "                                  mask_size[0], mask_size[1], -1))\n",
    "\n",
    "        # TODO: Fix batch_size > 1\n",
    "        boxes = boxes[0]\n",
    "        masks = masks[0]\n",
    "        annotations = annotations[0]\n",
    "        masks_target = masks_target[0]\n",
    "\n",
    "        # compute overlap of boxes with annotations\n",
    "        iou = overlap(boxes, annotations)\n",
    "        argmax_overlaps_inds = K.argmax(iou, axis=1)\n",
    "        max_iou = K.max(iou, axis=1)\n",
    "\n",
    "        # filter those with IoU > 0.5\n",
    "        indices = tf.where(K.greater_equal(max_iou, iou_threshold))\n",
    "        boxes = tf.gather_nd(boxes, indices)\n",
    "        masks = tf.gather_nd(masks, indices)\n",
    "        argmax_overlaps_inds = tf.gather_nd(argmax_overlaps_inds, indices)\n",
    "        argmax_overlaps_inds = K.cast(argmax_overlaps_inds, 'int32')\n",
    "        labels = K.gather(annotations[:, 4], argmax_overlaps_inds)\n",
    "        labels = K.cast(labels, 'int32')\n",
    "\n",
    "        # make normalized boxes\n",
    "        boxes = K.stack([\n",
    "            boxes[:, 1] / (K.cast(height, dtype=K.floatx()) - 1),  # y1\n",
    "            boxes[:, 0] / (K.cast(width, dtype=K.floatx()) - 1),   # x1\n",
    "            (boxes[:, 3] - 1) / (K.cast(height, dtype=K.floatx()) - 1),  # y2\n",
    "            (boxes[:, 2] - 1) / (K.cast(width, dtype=K.floatx()) - 1),   # x2\n",
    "        ], axis=1)\n",
    "\n",
    "        # crop and resize masks_target\n",
    "        # append a fake channel dimension\n",
    "        masks_target = K.expand_dims(masks_target, axis=3)\n",
    "        masks_target = tf.image.crop_and_resize(\n",
    "            masks_target, boxes, argmax_overlaps_inds, mask_size)\n",
    "        # remove fake channel dimension\n",
    "        masks_target = masks_target[:, :, :, 0]\n",
    "\n",
    "        # gather the predicted masks using the annotation label\n",
    "        masks = tf.transpose(masks, (0, 3, 1, 2))\n",
    "        label_indices = K.stack([tf.range(K.shape(labels)[0]), labels], axis=1)\n",
    "        masks = tf.gather_nd(masks, labels)\n",
    "\n",
    "        # compute mask loss\n",
    "        _mask_loss = K.binary_crossentropy(masks_target, masks)\n",
    "        normalizer = K.shape(masks)[0] * K.shape(masks)[1] * K.shape(masks)[2]\n",
    "        normalizer = K.maximum(K.cast(normalizer, K.floatx()), 1)\n",
    "        _mask_loss = K.sum(_mask_loss) / normalizer\n",
    "        return _mask_loss\n",
    "\n",
    "    return tf.cond(\n",
    "        K.any(K.equal(K.shape(y_true), 0)),\n",
    "        lambda: K.cast_to_floatx(0.0),\n",
    "        lambda: _mask(y_true, y_pred,\n",
    "                      iou_threshold=0.5,\n",
    "                      mask_size=(28, 28))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"filtered_detections\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"filtered_detections\".\n",
      "WARNING:tensorflow:Output \"filtered_detections\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"filtered_detections\".\n",
      "WARNING:tensorflow:Output \"filtered_detections\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"filtered_detections\".\n",
      "WARNING:tensorflow:Output \"mask_submodel\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"mask_submodel\".\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss={\n",
    "    'regression': regress_loss,\n",
    "    'classification': classification_loss,\n",
    "    'masks': mask_loss\n",
    "}, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import image_generators\n",
    "\n",
    "datagen = image_generators.RetinaNetGenerator(\n",
    "#     fill_mode='constant',  # for rotations\n",
    "    rotation_range=180,\n",
    "    shear_range=0,\n",
    "    zoom_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "datagen_val = image_generators.RetinaNetGenerator(\n",
    "#     fill_mode='constant',  # for rotations\n",
    "    rotation_range=0,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=0,\n",
    "    vertical_flip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Removing 598 of 5760 images with fewer than 3 objects.\n",
      "WARNING:tensorflow:Removing 150 of 1440 images with fewer than 3 objects.\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.retinanet_anchor_utils import make_shapes_callback\n",
    "from deepcell.utils.retinanet_anchor_utils import guess_shapes\n",
    "\n",
    "if 'vgg' in backbone or 'densenet' in backbone:\n",
    "    compute_shapes = make_shapes_callback(model)\n",
    "else:\n",
    "    compute_shapes = guess_shapes\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    {'X': X_train, 'y': y_train},\n",
    "    include_masks=True,\n",
    "    compute_shapes=compute_shapes,\n",
    "    batch_size=16)\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    {'X': X_test, 'y': y_test},\n",
    "    include_masks=True,\n",
    "    compute_shapes=compute_shapes,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import callbacks\n",
    "from deepcell.callbacks import *\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(LOG_DIR, model_name))\n",
    "\n",
    "training_callbacks = [\n",
    "    callbacks.LearningRateScheduler(lr_sched),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        os.path.join(MODEL_DIR, '{}.h5'.format(model_name)),\n",
    "        monitor='val_loss', verbose=1,\n",
    "        save_best_only=True, save_weights_only=False),\n",
    "    tensorboard_callback,\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', factor=0.1,\n",
    "        patience=10, verbose=1,\n",
    "        mode='auto', min_delta=0.0001,\n",
    "        cooldown=0, min_lr=0),\n",
    "    RedirectModel(\n",
    "        Evaluate(val_data,\n",
    "                 iou_threshold=0.5,\n",
    "                 score_threshold=0.01,\n",
    "                 max_detections=100,\n",
    "                 tensorboard=tensorboard_callback,\n",
    "                 weighted_average=True),\n",
    "        prediction_model),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(uid, i)\u001b[0m\n\u001b[1;32m    431\u001b[0m   \"\"\"\n\u001b[0;32m--> 432\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/image_generators.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m   2030\u001b[0m             \u001b[0manchor_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m             shapes_callback=self.compute_shapes)\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/retinanet_anchor_utils.py\u001b[0m in \u001b[0;36manchors_for_shape\u001b[0;34m(image_shape, pyramid_levels, anchor_params, shapes_callback)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mimage_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyramid_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/retinanet_anchor_utils.py\u001b[0m in \u001b[0;36mget_shapes\u001b[0;34m(image_shape, pyramid_levels)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyramid_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;31m# input_shape = tensor_shape.TensorShape(input_shape).as_list()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/retinanet_anchor_utils.py\u001b[0m in \u001b[0;36mlayer_shapes\u001b[0;34m(image_shape, model)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mcomputed_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/layers/retinanet.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_anchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    993\u001b[0m   \"\"\"\n\u001b[0;32m--> 994\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \"\"\"\n\u001b[0;32m--> 711\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5153\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f92ab764669c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     callbacks=training_callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."
     ]
    }
   ],
   "source": [
    "loss_history = model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.x.shape[0] // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.x.shape[0] // batch_size,\n",
    "    callbacks=training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepcell.training import train_model_retinanet\n",
    "\n",
    "# model = train_model_retinanet(\n",
    "#     model=model,\n",
    "#     backbone=backbone,\n",
    "#     dataset=DATA_FILE,  # full path to npz file\n",
    "#     model_name='retinanet',\n",
    "#     sigma=3.0,\n",
    "#     alpha=0.25,\n",
    "#     gamma=2.0,\n",
    "#     include_masks=True,  # include mask generation -> MaskRCNN\n",
    "#     weighted_average=True,\n",
    "#     score_threshold=0.01,\n",
    "#     iou_threshold=0.5,\n",
    "#     max_detections=100,\n",
    "#     test_size=test_size,\n",
    "#     optimizer=optimizer,\n",
    "#     batch_size=batch_size,\n",
    "#     n_epoch=n_epoch,\n",
    "#     log_dir=LOG_DIR,\n",
    "#     model_dir=MODEL_DIR,\n",
    "#     lr_sched=lr_sched,\n",
    "#     rotation_range=180,\n",
    "#     flip=True,\n",
    "#     shear=False,\n",
    "#     zoom_range=(0.8, 1.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deepcell.utils.plot_utils import draw_detections\n",
    "\n",
    "index = np.random.randint(low=0, high=X_test.shape[0])\n",
    "print('Image Number:', index)\n",
    "\n",
    "image, mask = X_test[index:index + 1], y_test[index:index + 1]\n",
    "\n",
    "boxes, scores, labels = prediction_model.predict(image)\n",
    "\n",
    "image = 0.01 * np.tile(np.expand_dims(image[0, ..., 0], axis=-1), (1, 1, 3))\n",
    "mask = np.squeeze(mask)\n",
    "\n",
    "# copy to draw on\n",
    "draw = image.copy()\n",
    "\n",
    "# draw the detections\n",
    "draw_detections(draw, boxes[0], scores[0], labels[0],\n",
    "                label_to_name=lambda x: 'cell',\n",
    "                score_threshold=0.5,)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap='jet')\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(mask, cmap='jet')\n",
    "ax[1].set_title('Labeled Data')\n",
    "\n",
    "ax[2].imshow(draw, cmap='jet')\n",
    "ax[2].set_title('Detections')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
